{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd1b2f3",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e59ccd",
   "metadata": {},
   "source": [
    "### Tan Kar Min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19deeb84",
   "metadata": {},
   "source": [
    "## Chapter 1 Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea85c36",
   "metadata": {},
   "source": [
    "### 1.1 Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e19694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb916c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Training dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e50d52",
   "metadata": {},
   "source": [
    "### 1.2 Overview of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de6c9583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85413b18",
   "metadata": {},
   "source": [
    "The given dataset contains 2100 observations and 24 variables, out of which 23 are features and 1 is the label, representing the credit score. The features include demographic information about bank users such as age, occupation, annual income, monthly inhand salary, as well as credit-related data such as the number of credit cards, credit mix, and outstanding debts. The label, credit score, is divided into three categories, which are 1-poor, 2-standard and 3-good. The first 10 records of the dataset provide a brief overview of these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76ea11c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106981</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>14619.585</td>\n",
       "      <td>1005.298750</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>125.33</td>\n",
       "      <td>38.883189</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>11.620889</td>\n",
       "      <td>32.846250</td>\n",
       "      <td>202</td>\n",
       "      <td>279.724565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108774</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>70883.440</td>\n",
       "      <td>5663.953333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>604.77</td>\n",
       "      <td>31.131854</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>97.133997</td>\n",
       "      <td>39.858686</td>\n",
       "      <td>201</td>\n",
       "      <td>526.033197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111896</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>14395.830</td>\n",
       "      <td>1027.652500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2841.00</td>\n",
       "      <td>37.587389</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>74.795382</td>\n",
       "      <td>31.947738</td>\n",
       "      <td>201</td>\n",
       "      <td>258.713002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32731</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11189.065</td>\n",
       "      <td>1159.422083</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>761.18</td>\n",
       "      <td>33.980973</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>18.439801</td>\n",
       "      <td>16.806258</td>\n",
       "      <td>201</td>\n",
       "      <td>324.284100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128760</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>78956.730</td>\n",
       "      <td>6523.727500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>436.82</td>\n",
       "      <td>27.684657</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>128.558654</td>\n",
       "      <td>70.788144</td>\n",
       "      <td>102</td>\n",
       "      <td>669.025667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151390</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>21167.555</td>\n",
       "      <td>1829.962917</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1286.57</td>\n",
       "      <td>33.708627</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>40.335282</td>\n",
       "      <td>22.819491</td>\n",
       "      <td>202</td>\n",
       "      <td>277.370503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69108</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>44964.220</td>\n",
       "      <td>3898.018333</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>210.15</td>\n",
       "      <td>28.666651</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>75.407970</td>\n",
       "      <td>46.850154</td>\n",
       "      <td>201</td>\n",
       "      <td>306.094503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26275</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>140390.320</td>\n",
       "      <td>11888.193330</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1423.23</td>\n",
       "      <td>32.966273</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>182.160424</td>\n",
       "      <td>133.213034</td>\n",
       "      <td>103</td>\n",
       "      <td>1020.195699</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>139554</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>54284.940</td>\n",
       "      <td>4673.745000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4237.27</td>\n",
       "      <td>38.040801</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>190.641975</td>\n",
       "      <td>73.850532</td>\n",
       "      <td>101</td>\n",
       "      <td>392.593676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99702</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>19375.760</td>\n",
       "      <td>1633.646667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1053.72</td>\n",
       "      <td>31.459343</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>10.511619</td>\n",
       "      <td>26.628272</td>\n",
       "      <td>103</td>\n",
       "      <td>335.390534</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Month  Age  Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0  106981      8   41           2      14619.585            1005.298750   \n",
       "1  108774      1   28          12      70883.440            5663.953333   \n",
       "2  111896      3   29          12      14395.830            1027.652500   \n",
       "3   32731      2   25           1      11189.065            1159.422083   \n",
       "4  128760      7   37           3      78956.730            6523.727500   \n",
       "5  151390      5   50          11      21167.555            1829.962917   \n",
       "6   69108      7   43          14      44964.220            3898.018333   \n",
       "7   26275      7   50          13     140390.320           11888.193330   \n",
       "8  139554      1   29           6      54284.940            4673.745000   \n",
       "9   99702      1   18           3      19375.760            1633.646667   \n",
       "\n",
       "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  ...  \\\n",
       "0                  7                7             19            1  ...   \n",
       "1                  4                4             10            3  ...   \n",
       "2                  8                8             28            7  ...   \n",
       "3                  6                3             15            3  ...   \n",
       "4                  7                3             14            2  ...   \n",
       "5                  2                7              9            3  ...   \n",
       "6                  6                7             15            3  ...   \n",
       "7                  5                2              4            3  ...   \n",
       "8                  7                8             30            7  ...   \n",
       "9                  4                3              6            1  ...   \n",
       "\n",
       "   Credit_Mix  Outstanding_Debt  Credit_Utilization_Ratio  Credit_History_Age  \\\n",
       "0           2            125.33                 38.883189                 222   \n",
       "1           2            604.77                 31.131854                 356   \n",
       "2           1           2841.00                 37.587389                  27   \n",
       "3           2            761.18                 33.980973                 126   \n",
       "4           2            436.82                 27.684657                 265   \n",
       "5           3           1286.57                 33.708627                 361   \n",
       "6           2            210.15                 28.666651                 400   \n",
       "7           3           1423.23                 32.966273                 374   \n",
       "8           1           4237.27                 38.040801                  59   \n",
       "9           2           1053.72                 31.459343                 325   \n",
       "\n",
       "   Payment_of_Min_Amount  Total_EMI_per_month  Amount_invested_monthly  \\\n",
       "0                      1            11.620889                32.846250   \n",
       "1                      0            97.133997                39.858686   \n",
       "2                      1            74.795382                31.947738   \n",
       "3                      0            18.439801                16.806258   \n",
       "4                      1           128.558654                70.788144   \n",
       "5                      0            40.335282                22.819491   \n",
       "6                      0            75.407970                46.850154   \n",
       "7                      0           182.160424               133.213034   \n",
       "8                      1           190.641975                73.850532   \n",
       "9                      1            10.511619                26.628272   \n",
       "\n",
       "   Payment_Behaviour  Monthly_Balance  Credit_Score  \n",
       "0                202       279.724565             2  \n",
       "1                201       526.033197             2  \n",
       "2                201       258.713002             1  \n",
       "3                201       324.284100             2  \n",
       "4                102       669.025667             2  \n",
       "5                202       277.370503             1  \n",
       "6                201       306.094503             2  \n",
       "7                103      1020.195699             3  \n",
       "8                101       392.593676             2  \n",
       "9                103       335.390534             2  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb52850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83333.452381</td>\n",
       "      <td>4.411429</td>\n",
       "      <td>33.197143</td>\n",
       "      <td>7.927619</td>\n",
       "      <td>51244.805155</td>\n",
       "      <td>4255.554221</td>\n",
       "      <td>5.407143</td>\n",
       "      <td>5.576667</td>\n",
       "      <td>14.532857</td>\n",
       "      <td>3.50619</td>\n",
       "      <td>...</td>\n",
       "      <td>2.057619</td>\n",
       "      <td>1444.016295</td>\n",
       "      <td>32.379813</td>\n",
       "      <td>221.545714</td>\n",
       "      <td>0.522381</td>\n",
       "      <td>110.411491</td>\n",
       "      <td>56.302384</td>\n",
       "      <td>153.554762</td>\n",
       "      <td>399.349997</td>\n",
       "      <td>1.865714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41013.880408</td>\n",
       "      <td>2.279068</td>\n",
       "      <td>10.754180</td>\n",
       "      <td>4.325104</td>\n",
       "      <td>38801.235929</td>\n",
       "      <td>3226.388893</td>\n",
       "      <td>2.553747</td>\n",
       "      <td>2.099327</td>\n",
       "      <td>8.736433</td>\n",
       "      <td>2.47685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>1186.545886</td>\n",
       "      <td>5.199365</td>\n",
       "      <td>100.110503</td>\n",
       "      <td>0.499618</td>\n",
       "      <td>138.536282</td>\n",
       "      <td>40.246618</td>\n",
       "      <td>49.702836</td>\n",
       "      <td>203.955200</td>\n",
       "      <td>0.674920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10033.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7011.685000</td>\n",
       "      <td>319.556250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>21.359116</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>7.438257</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48108.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>19696.500000</td>\n",
       "      <td>1641.972917</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>566.605000</td>\n",
       "      <td>28.059563</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.488358</td>\n",
       "      <td>27.842413</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>269.255129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81490.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37087.920000</td>\n",
       "      <td>3101.737500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1149.035000</td>\n",
       "      <td>32.402470</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.878526</td>\n",
       "      <td>46.803308</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>337.412112</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118895.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>73327.380000</td>\n",
       "      <td>6118.762500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2001.147500</td>\n",
       "      <td>36.641141</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.882432</td>\n",
       "      <td>73.229307</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>473.138717</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>155610.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>179987.280000</td>\n",
       "      <td>15101.940000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4997.100000</td>\n",
       "      <td>46.724651</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1779.103254</td>\n",
       "      <td>297.064670</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1181.113695</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID        Month          Age   Occupation  Annual_Income  \\\n",
       "count    2100.000000  2100.000000  2100.000000  2100.000000    2100.000000   \n",
       "mean    83333.452381     4.411429    33.197143     7.927619   51244.805155   \n",
       "std     41013.880408     2.279068    10.754180     4.325104   38801.235929   \n",
       "min     10033.000000     1.000000    14.000000     1.000000    7011.685000   \n",
       "25%     48108.000000     2.000000    24.000000     4.000000   19696.500000   \n",
       "50%     81490.000000     4.000000    33.000000     8.000000   37087.920000   \n",
       "75%    118895.250000     6.000000    42.000000    12.000000   73327.380000   \n",
       "max    155610.000000     8.000000    56.000000    15.000000  179987.280000   \n",
       "\n",
       "       Monthly_Inhand_Salary  Num_Bank_Accounts  Num_Credit_Card  \\\n",
       "count            2100.000000        2100.000000      2100.000000   \n",
       "mean             4255.554221           5.407143         5.576667   \n",
       "std              3226.388893           2.553747         2.099327   \n",
       "min               319.556250           0.000000         0.000000   \n",
       "25%              1641.972917           4.000000         4.000000   \n",
       "50%              3101.737500           6.000000         5.000000   \n",
       "75%              6118.762500           7.000000         7.000000   \n",
       "max             15101.940000          11.000000        11.000000   \n",
       "\n",
       "       Interest_Rate  Num_of_Loan  ...   Credit_Mix  Outstanding_Debt  \\\n",
       "count    2100.000000   2100.00000  ...  2100.000000       2100.000000   \n",
       "mean       14.532857      3.50619  ...     2.057619       1444.016295   \n",
       "std         8.736433      2.47685  ...     0.731132       1186.545886   \n",
       "min         1.000000      0.00000  ...     1.000000          0.230000   \n",
       "25%         7.000000      2.00000  ...     2.000000        566.605000   \n",
       "50%        13.000000      3.00000  ...     2.000000       1149.035000   \n",
       "75%        20.000000      5.00000  ...     3.000000       2001.147500   \n",
       "max        34.000000      9.00000  ...     3.000000       4997.100000   \n",
       "\n",
       "       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "count               2100.000000         2100.000000            2100.000000   \n",
       "mean                  32.379813          221.545714               0.522381   \n",
       "std                    5.199365          100.110503               0.499618   \n",
       "min                   21.359116            4.000000               0.000000   \n",
       "25%                   28.059563          142.000000               0.000000   \n",
       "50%                   32.402470          219.000000               1.000000   \n",
       "75%                   36.641141          303.000000               1.000000   \n",
       "max                   46.724651          403.000000               1.000000   \n",
       "\n",
       "       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "count          2100.000000              2100.000000        2100.000000   \n",
       "mean            110.411491                56.302384         153.554762   \n",
       "std             138.536282                40.246618          49.702836   \n",
       "min               0.000000                 0.000000         101.000000   \n",
       "25%              27.488358                27.842413         102.000000   \n",
       "50%              67.878526                46.803308         201.000000   \n",
       "75%             146.882432                73.229307         201.000000   \n",
       "max            1779.103254               297.064670         203.000000   \n",
       "\n",
       "       Monthly_Balance  Credit_Score  \n",
       "count      2100.000000   2100.000000  \n",
       "mean        399.349997      1.865714  \n",
       "std         203.955200      0.674920  \n",
       "min           7.438257      1.000000  \n",
       "25%         269.255129      1.000000  \n",
       "50%         337.412112      2.000000  \n",
       "75%         473.138717      2.000000  \n",
       "max        1181.113695      3.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59154e05",
   "metadata": {},
   "source": [
    "The summary statistics of the dataset indicate that the average value of each feature varies significantly from one another. Some features, including outstanding debt, annual income, and monthly in-hand salary, have a large standard deviation. The count of all features is 2100, which suggests that there are no incomplete entries in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca78168",
   "metadata": {},
   "source": [
    "## Chapter 2 Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed53ab",
   "metadata": {},
   "source": [
    "### 2.1 Introduction to supervised machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6059b",
   "metadata": {},
   "source": [
    "Supervised machine learning is a type of machine learning where the algorithm is trained on a labelled dataset [1]. Labelled data refers to the dataset that contains both the input variables and the corresponding output variables (label). In supervised learning, the data is divided into input variables (features) and output variables (labels). The algorithm predicts the output variable of new unseen data based on the feature variables by learning on patterns in the labelled training dataset [1]. \n",
    "\n",
    "Supervised learning entails two distinct types of learning: classification and regression. Regression is used when the output is continuous. By contrast, classification is used when the output is categorical. For this particular task, we will be using a classification supervised machine learning model to predict and categorize individuals into specific credit score brackets.\n",
    "\n",
    "To train a supervised learning algorithm, it is important to split the labelled dataset into a training set and a test set. The training set is used to train the model, and the test set is used to evaluate the performance of the trained model on new, unseen data [1]. The training set is typically larger than the test set, and the data is randomly sampled to avoid bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cff469",
   "metadata": {},
   "source": [
    "### 2.2 Separating the features and the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6a80a",
   "metadata": {},
   "source": [
    "Prior to building the model, the dataset is separated into an input dataset (basic bank details and credit-related information) and a corresponding output or label dataset (credit score). \n",
    "\n",
    "Certain features that were considered insignificant in determining an individual's credit score were eliminated. The decision to exclude these features were based on their correlation with the credit score, with those having a correlation coefficient below 0.1 being excluded. Additionally, the monthly inhand salary was removed as having both annual income and monthly inhand income seems redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd0375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         -0.026606\n",
       "Month                      -0.005878\n",
       "Age                         0.126065\n",
       "Occupation                 -0.028465\n",
       "Annual_Income               0.221317\n",
       "Monthly_Inhand_Salary       0.216986\n",
       "Num_Bank_Accounts          -0.368232\n",
       "Num_Credit_Card            -0.413036\n",
       "Interest_Rate              -0.474586\n",
       "Num_of_Loan                -0.373984\n",
       "Delay_from_due_date        -0.409188\n",
       "Num_of_Delayed_Payment     -0.372057\n",
       "Changed_Credit_Limit       -0.168301\n",
       "Num_Credit_Inquiries       -0.426879\n",
       "Credit_Mix                  0.484907\n",
       "Outstanding_Debt           -0.379331\n",
       "Credit_Utilization_Ratio    0.077528\n",
       "Credit_History_Age          0.395466\n",
       "Payment_of_Min_Amount      -0.376792\n",
       "Total_EMI_per_month         0.015477\n",
       "Amount_invested_monthly     0.179008\n",
       "Payment_Behaviour          -0.106978\n",
       "Monthly_Balance             0.225686\n",
       "Credit_Score                1.000000\n",
       "Name: Credit_Score, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examining the correlation of each feratures with credit score\n",
    "corr=dataset.corr()\n",
    "corr.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdea888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset and excluding features\n",
    "X = dataset.drop(['Credit_Score','ID', 'Month', 'Occupation', 'Monthly_Inhand_Salary', 'Credit_Utilization_Ratio', 'Total_EMI_per_month'], axis=1).values # Input Data\n",
    "y = dataset.iloc[:, -1].values # Label Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500cdb1",
   "metadata": {},
   "source": [
    "### 2.3 Spliting dataset for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abac761",
   "metadata": {},
   "source": [
    "The train_test_split() function from sklearn.model_selection is used to split the dataset into 80% training dataset and 20% testing dataset randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f94aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286cde3",
   "metadata": {},
   "source": [
    "It was observed that the number of observations in each credit score categories are not balance in the training dataset. To avoid bias, the RandomOverSampler function is used to over-sample the minority classes by picking samples at random with replacement [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b031ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    900\n",
      "1    506\n",
      "3    274\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each credit score categories in training dataset\n",
    "y_train_series = pd.Series(y_train)\n",
    "value_counts = y_train_series.value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e642edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Define the oversampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and apply the oversampling to the data\n",
    "X_train, y_train= oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd1b8c",
   "metadata": {},
   "source": [
    "## Chapter 3 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076ed22",
   "metadata": {},
   "source": [
    "### 3.1 Introduction to binary and multi-class classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df103e",
   "metadata": {},
   "source": [
    "The classification machine learning model is further divided into two categories, binary and multi-class classification. The main difference between binary and multi-class classification is the number of possible classes or categories that the classifier can predict. In binary classification, there are only two possible outcomes, while in multi-class classification, there are three or more possible outcomes.\n",
    "\n",
    "In binary classification, the input data is analyzed and classified into one of two possible classes, such as \"Yes\" or \"No\" or \"True\" or \"False\".\n",
    "\n",
    "In multi-class classification, the input data is analyzed and classified into one of three or more possible classes, such as \"small,\" \"medium,\" or \"large,\" or \"low,\" \"medium,\" or \"high.\"\n",
    "\n",
    "In this assignment, the target outcome of the intellegent system is divided into 3 different credit score categories (poor, standard or good). Hence, a multi-class classification model will be employed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a9cd4",
   "metadata": {},
   "source": [
    "### 3.2 Feature Scaling or Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996e594",
   "metadata": {},
   "source": [
    "Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without feature scaling or normalization. This is particularly important in models that consider the distance between observations [3]. Most classifiers use the Euclidean distance to measure the distance between two points. If one feature has a wide range of values, it can dominate the distance calculation [3]. To ensure that each feature has an equal impact on the final distance, it is important to normalize the range of all features, so that they are comparable and have the same scale [3].\n",
    "\n",
    "In the context of this assignment, it is crucial to perform feature scaling as we are using Support Vector Machine (SVM) for classification. The SVM algorithm needs to determine a decision boundary between different classes in the dataset [4]. This boundary is chosen to maximize the distance from the nearest points from different classes[4]. Therefore, the distance between data points plays a significant role in determining the decision boundary of the SVM classifier. Furthermore, based on the summary statistics of the dataset, it is evident that the features are on different scales and range. This indicates the need for scaling or normalization of the data to ensure proportionate contribution of each feature to the final distance.\n",
    "\n",
    "A built in function StandardScaler() from sklearn.preprocessing is used to normalize the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "851a9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) #scale it to have a mean of 0 and a certain standard deviation\n",
    "X_test = scaler.transform(X_test) # apply the mean and standard deviation to the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b595821",
   "metadata": {},
   "source": [
    "### 3.3 Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb27e9",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVMs) are a type of machine learning algorithm used for supervised learning. It is generally used as a classifier, but it can also be employed in regression problems [4]. SVM is commonly used in various applications such as face detection, classification of genes, and handwriting recognition[4].\n",
    "\n",
    "In linear regression, the algorithm aims to find the best-fit line that explains the relationship between the input and output variables. The relationship between the input and output variables is assumed to be linear, and the algorithm tries to minimize the sum of squared errors between the predicted and actual values. Unlike SVM, linear regression cannot handle classfication problems well. In contrast, SVM algorithm aims to create a hyperplane that separates the data into different classes, and the algorithm achieves this by finding the points closest to the line from all the classes, which are known as support vectors [4]. The distance between the hyperplane and the support vectors is known as the margin, and the algorithm aims to find the hyperplane that maximizes this margin [4].\n",
    "\n",
    "Compared to linear regression, SVM are more suitable for classification tasks and can handle non-linearly separable data by transforming the low-dimensional input space to a higher-dimensional feature space using a kernel function [4]. The kernel function maps the input data to a higher dimensional space, making it more efficient and accurate in separating complex problems [4].\n",
    "\n",
    "Here are some commonly used kernel:\n",
    "\n",
    "1) Linear Kernel: A linear kernel is a simple kernel that can be used as a dot product of two given observations. It is useful for linearly separable data, where the decision boundary is a straight line [4].\n",
    "\n",
    "2) Polynomial Kernel: The polynomial kernel is a more generalized form of the linear kernel. It can handle curved or nonlinear input spaces by transforming them into a higher dimensional space. A higher degree polynomial can capture more complex relationships between the input variables [4].\n",
    "\n",
    "3) Radial Basis Function (rbf) Kernel: The rbf kernel is a popular kernel function used in SVM classification. It maps the input space into an infinite dimensional space, which makes it useful for handling non-linearly separable data. The rbf kernel function is of the form K(x, xi) = exp(-gamma * sum((x – xi^2)), where gamma is a parameter that controls the shape of the decision boundary. The rbf kernel is useful for capturing complex relationships between the input variables [4].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394eb49",
   "metadata": {},
   "source": [
    "The SVM model for this assignment were built with a rbf kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe6865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.25, gamma=&#x27;auto&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.25, gamma=&#x27;auto&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.25, gamma='auto', random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf', C=0.25, gamma='auto', random_state=0) \n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad1805",
   "metadata": {},
   "source": [
    "## Chapter 4 Prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5893ec",
   "metadata": {},
   "source": [
    "The SVM model built was tested agaisnt the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the output for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adaf36",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccbd833",
   "metadata": {},
   "source": [
    "Confusion matrix for visualising the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ddfb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>114</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1    2   3\n",
       "1  94   14  24\n",
       "2  43  114  49\n",
       "3   3   13  66"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#add labels to the matrix for better visualisation\n",
    "labels = [1,2,3]\n",
    "cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33650d45",
   "metadata": {},
   "source": [
    "The rows of the confusion matrix represent the actual value while the columns represent predicted values [5].\n",
    "\n",
    "Hence, accordinng to the confusion matrix:\n",
    "\n",
    "Credit score 1:\n",
    "\n",
    "Among the 140 credit score 1 predicted by the model, 94 were actually score 1, while 43 were score 2 incorrectly predicted to be score 1 and 3 were score 3 incorrectly predicted to be score 1. 14 individuals of score 1 were falsely predicted as score 2 and 24 were falsely predicted as score 3.\n",
    "\n",
    "Precision: 94 / (94 + 43 + 3) = 0.671, Recall: 94 / (94 + 14 + 24) = 0.712\n",
    "\n",
    "Credit score 2:\n",
    "\n",
    "Among the 141 credit score 2 predicted by the model, 114 were actually score 2, while 14 were score 1 incorrectly predicted to be score 2 and 13 were score 3 incorrectly predicted to be score 2. 43 individuals of score 2 were falsely predicted as score 1 and 49 were falsely predicted as score 3.\n",
    "\n",
    "Precision: 114 / (14 + 114 + 13) = 0.809, Recall: 114 / (43 + 114 + 49) = 0.553\n",
    "\n",
    "Credit score 3:\n",
    "\n",
    "Among the 139 credit score 3 predicted by the model, 66 were actually score 3, while 24 were score 1 incorrectly predicted to be score 3 and 49 were score 2 incorrectly predicted to be score 3. 3 individuals of score 3 were falsely predicted as score 1 and 13 were falsely predicted as score 2.\n",
    "\n",
    "Precision: 66 / (24 + 49 + 66) = 0.475, Recall: 66 / (3 + 13 + 66) = 0.805\n",
    "\n",
    "\n",
    "The accuracy counted based on the confusion matrix are as below:\n",
    "(94 + 114 + 66) / (94 + 14 + 24 + 43 + 114 + 49 + 3 + 13 + 66) = 0.652"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7e7ea",
   "metadata": {},
   "source": [
    "### 4.2 Quadratic Weighted Kappa (QWK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486d645",
   "metadata": {},
   "source": [
    "Quadratic Weighted Kappa (QWK) is a statistical measure used to assess the agreement between two outcomes who assign scores or ratings to a set of items [6]. The QWK coefficient is calculated using the observed agreement between the algorithm's prediction and true labels, taking into account the possibility of agreement by chance [6]. It ranges from -1 to 1, with values closer to 1 indicating a higher level of agreement. -1 indicates a complete disagreement, 0 indicates a random agreement and 1 indicates a complete agreement [6]. \n",
    "\n",
    "QWK takes into account not only the number of ratings that agree but also the degree of disagreement between the ratings [6]. It assign different weights based on the differences between actual and predicted values, which is particularly useful when the scale being used has many categories [6].\n",
    "\n",
    "The QWK calculation involves four steps. First, a histogram matrix is created that shows a rating of i (actual) that received a predicted value j. [6]. Second, a matrix of weights is constructued by calculating the difference between actual and predicted values. Third, a histogram matrix of expected rating is calculated, assuming no correlation between rating scores [6]. Finally, the QWK is calculated using the three histograms, with a higher QWK value indicating better agreement between the two sets of ratings [6]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e290e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK score: 0.5393312717433321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "qwk_score = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n",
    "\n",
    "print(\"QWK score:\", qwk_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9f26f",
   "metadata": {},
   "source": [
    "It was stated that a QWK score of 0.4-0.6 is considered as having a good agreement [6]. Our model gives a QWK score of 0.539, suggesting that the model has a relative good performance but not yet optimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06be464",
   "metadata": {},
   "source": [
    "## Chapter 5 Kaggle Submission Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451857d0",
   "metadata": {},
   "source": [
    "The “FIT1043-Credit-Scores-Submission.csv” file consists of 900 rows of features data with no labels (credit score). The SVM model built was used to predict the credit score for individuals in this dataset. The predicted output will be submitted to Kaggle as a part of the in class competition. The output is evaluated using QWK in the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e49690f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import files\n",
    "#feature dataset\n",
    "subdataset = pd.read_csv(\"Prediction dataset.csv\")\n",
    "#submission file template\n",
    "submissionfile = pd.read_csv(\"Submission template.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff7ec894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude unused features\n",
    "Xsub = subdataset.drop(['ID', 'Month', 'Occupation', 'Monthly_Inhand_Salary', 'Credit_Utilization_Ratio', 'Total_EMI_per_month'], axis=1).values\n",
    "#scale the dataset\n",
    "Xsub = scaler.transform(Xsub) # apply the mean and standard deviation to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c59e427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict credit score using the SVM model built\n",
    "ysub_pred = clf.predict(Xsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec242882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the predicted credit score to the submission file\n",
    "submissionfile['Credit_Score']=ysub_pred\n",
    "submissionfile.to_csv(\"Prediction result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c5c48",
   "metadata": {},
   "source": [
    "## Chapter 6 Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed13a93",
   "metadata": {},
   "source": [
    "To summarize, this assignment involved developing a multi-class supervised machine learning model that categorizes bank users into three credit score categories - poor (1), standard (2), and good (3) - based on their bank details and credit-related information. The model was built using the support vector machine algorithm with a rbf kernel. The evaluation of the final model using the testing dataset achieved an accuracy of 0.652 and a QWK score of 0.539. The Kaggle submission prediction achieved a QWK score of 0.556. Hence, the SVM model built in this assignment was suggest to have a moderate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d1e50",
   "metadata": {},
   "source": [
    "## Chapter 7 Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31128e7",
   "metadata": {},
   "source": [
    "[1] javatpoint (2022). Supervised Machine learning - Javatpoint. [online] www.javatpoint.com. Available at: https://www.javatpoint.com/supervised-machine-learning.\n",
    "\n",
    "[2] Brownlee, J. (2020). Random Oversampling and Undersampling for Imbalanced Classification. [online] Machine Learning Mastery. Available at: https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/.\n",
    "\n",
    "[3] Roy, B. (2020). All about Feature Scaling. [online] Medium. Available at: https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35.\n",
    "\n",
    "[4] Navlani, A. (2019). Support Vector Machines with Scikit-learn Tutorial. [online] datacamp. Available at: https://www.datacamp.com/tutorial/svm-classification-scikit-learn-python.\n",
    "\n",
    "[5] Bharathi (2021). Confusion Matrix for Multi-Class Classification. [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/.\n",
    "\n",
    "[6] BANERJEE, P. (2020). Simple Explanation of Quadratic Weighted Kappa. [online] kaggle.com. Available at: https://www.kaggle.com/code/prashant111/simple-explanation-of-quadratic-weighted-kappa/notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
